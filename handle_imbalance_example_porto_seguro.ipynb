{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for reading data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import library for visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# import library for preprocessing data\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# import library for making pipelines\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# import library for sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# import library for time comparision\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0              0              0              1              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              0              1              0              0  ...   \n",
       "4              0              1              0              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to show examples about how I handle imbalanced classification problems. The data source is from Porto Seguro, one of Brazil’s largest auto and homeowner insurance companies. The problem is to predict if a driver will initiate an auto insurance claim. Here is a link for this data source: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a22fbe2e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualization imbalance\n",
    "sns.countplot(x = 'target', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>counts</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>573518</td>\n",
       "      <td>96.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21694</td>\n",
       "      <td>3.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  counts     pct\n",
       "0       0  573518  96.355\n",
       "1       1   21694   3.645"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0, 1]\n",
    "counts = df['target'].value_counts()\n",
    "pct = round(df['target'].value_counts() / df['target'].value_counts().sum() * 100, 3)\n",
    "table = zip(y, counts, pct)\n",
    "table = pd.DataFrame(table, columns = ['target', 'counts', 'pct'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.963\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "CV time: 805.219s\n"
     ]
    }
   ],
   "source": [
    "# regular pipeline\n",
    "def regular_pipeline():\n",
    "    # read data\n",
    "    df = pd.read_csv('train.csv')\n",
    "    \n",
    "    # split data\n",
    "    y = df['target']\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    # preprocess data\n",
    "    num_cols = X.columns[X.dtypes == 'float64']\n",
    "\n",
    "    ## handle numerical variable: input median, standard scaler in linear method\n",
    "    num_proc_nlin = make_pipeline(SimpleImputer(missing_values = -1, strategy = 'median'))\n",
    "\n",
    "    processor_nlin = make_column_transformer(\n",
    "        (num_proc_nlin, num_cols),\n",
    "        remainder = 'passthrough')\n",
    "    \n",
    "    # run CV with classifier\n",
    "    pipe = make_pipeline(processor_nlin, RandomForestClassifier())\n",
    "    start = time.time()\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv = 5, scoring = ['accuracy', 'recall', 'f1'])\n",
    "    stop = time.time()\n",
    "    print ('accuracy: ' + str(round(scores['test_accuracy'].mean(), 3)))\n",
    "    print ('recall: ' + str(round(scores['test_recall'].mean(), 3)))\n",
    "    print ('f1: ' + str(round(scores['test_f1'].mean(), 3)))\n",
    "    print (f\"CV time: {round(stop - start, 3)}s\")\n",
    "    \n",
    "regular_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data with more than 590k of record is severely imbalanced, where more than 96% of driver do not claim an auto insurance. As shown above, a CV is run on 80% data with a usual classification pipeline. A RandomForestClassifier is used here since categorical variables are label-encoded, a non-linear method makes more sense without further encoding. Again this notebook does not focus on data preprocessing, but showing an example to handle imbalanced data.\n",
    "\n",
    "A model with 96% accuracy may delight people, but I never want to see a classification model with 0% recall. This number implies that our model treats minority class as noise during training, which does not make sense. The reason why we need to model this insurance data is to find out bad drivers, raise the cost of insurance for bad drivers and reduce the price for good ones. If we treat minority class as noise, we are asking good drivers to pay as much as bad drivers with the assumption that good drivers are much less likely to claim insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions\n",
    "The first problem to address is sampling. I make sure to use stratified sampling when I sample data especially in CV to make sure that each fold has samples for minority class.\n",
    "\n",
    "The second thing I would like to do is to put more weights on minority class while training. There are 3 ways to do so.\n",
    "1. Oversampling samples with the minority class\n",
    "2. Undersampling samples with the majority class\n",
    "3. Hyperparameter Tuning\n",
    "\n",
    "Here is a regular pipeline with a sampler. Due to data size, using an oversampler will cost too much time to run a CV. Hence in the following section, examples of an undersampler and xgboost hyperparameter are provided without an oversampler example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_with_sampler(sampler, classifier):\n",
    "    # read data\n",
    "    df = pd.read_csv('train.csv')\n",
    "    \n",
    "    # split data\n",
    "    y = df['target']\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "    \n",
    "    # preprocess data\n",
    "    num_cols = X.columns[X.dtypes == 'float64']\n",
    "\n",
    "    ## handle numerical variable: input median, standard scaler in linear method\n",
    "    num_proc_nlin = make_pipeline(SimpleImputer(missing_values = -1, strategy = 'median'))\n",
    "\n",
    "    processor_nlin = make_column_transformer(\n",
    "        (num_proc_nlin, num_cols),\n",
    "        remainder = 'passthrough')\n",
    "    \n",
    "    # run CV with classifier\n",
    "    pipe = make_pipeline(processor_nlin, sampler, classifier)\n",
    "    start = time.time()\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv = 5, scoring = ['accuracy', 'recall', 'f1'])\n",
    "    stop = time.time()\n",
    "    print ('accuracy: ' + str(round(scores['test_accuracy'].mean(), 3)))\n",
    "    print ('recall: ' + str(round(scores['test_recall'].mean(), 3)))\n",
    "    print ('f1: ' + str(round(scores['test_f1'].mean(), 3)))\n",
    "    print (f\"CV time: {round(stop - start, 3)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Undersampling majority class in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.605\n",
      "recall: 0.558\n",
      "f1: 0.093\n",
      "CV time: 50.191s\n"
     ]
    }
   ],
   "source": [
    "pipeline_with_sampler(RandomUnderSampler(), RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using undersampler, training time is much faster, but we lose some information from data. Undersampler may only be used when data is large enough so that the undersample can be representative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.717\n",
      "recall: 0.419\n",
      "f1: 0.097\n",
      "CV time: 266.64s\n"
     ]
    }
   ],
   "source": [
    "def xgboost_pipeline():\n",
    "    # read data\n",
    "    df = pd.read_csv('train.csv')\n",
    "    \n",
    "    # split data\n",
    "    y = df['target']\n",
    "    X = df.drop(columns = ['target'])\n",
    "    X_train, X_holdout, y_train, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)\n",
    "    \n",
    "    # preprocess data\n",
    "    num_cols = X.columns[X.dtypes == 'float64']\n",
    "\n",
    "    ## handle numerical variable: input median, standard scaler in linear method\n",
    "    num_proc_nlin = make_pipeline(SimpleImputer(missing_values = -1, strategy = 'median'))\n",
    "\n",
    "    processor_nlin = make_column_transformer(\n",
    "        (num_proc_nlin, num_cols),\n",
    "        remainder = 'passthrough')\n",
    "    \n",
    "    # run CV with classifier\n",
    "    pipe = make_pipeline(processor_nlin, xgb.XGBClassifier(scale_pos_weight = 573518/21694))\n",
    "    start = time.time()\n",
    "    scores = cross_validate(pipe, X_train, y_train, cv = 5, scoring = ['accuracy', 'recall', 'f1'])\n",
    "    stop = time.time()\n",
    "    print ('accuracy: ' + str(round(scores['test_accuracy'].mean(), 3)))\n",
    "    print ('recall: ' + str(round(scores['test_recall'].mean(), 3)))\n",
    "    print ('f1: ' + str(round(scores['test_f1'].mean(), 3)))\n",
    "    print (f\"CV time: {round(stop - start, 3)}s\")\n",
    "    \n",
    "xgboost_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some boosting methods like xgboost and lightgbm have a hyperparameter called scale_pos_weight that handle sample weights of positive class. Here I just simply use the ratio of negative class over positive class to show an example. By this mean, we do not lose data information but handle imbalanced data in a faster way than oversampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
